{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2TdwqkGUbdcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxl6opbUFuru",
        "outputId": "62a78dbb-2952-46b7-b0d5-a93690ce1c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 6.12%\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "    if len(true_labels) != len(predicted_labels):\n",
        "        raise ValueError(\"Both lists must have the same length.\")\n",
        "\n",
        "    correct_count = 0\n",
        "    for true, predicted in zip(true_labels, predicted_labels):\n",
        "        if predicted and true == predicted:\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = (correct_count / len(true_labels)) * 100\n",
        "    return accuracy\n",
        "\n",
        "df = pd.read_csv('litqa.csv')\n",
        "\n",
        "\n",
        "true_labels = list(df['true_litqa'].values)\n",
        "predicted_labels = list(df['prediction_litqa'].values)\n",
        "\n",
        "accuracy = calculate_accuracy(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh_KG3JKHfwo",
        "outputId": "1dcb0e55-3e60-4c3a-f37f-6cf0d797223b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('pubmedqa.csv')\n",
        "true_labels = list(df['true_pubmedqa'].values)\n",
        "predicted_labels = list(df['prediction_pubmedqa'].values)"
      ],
      "metadata": {
        "id": "RhjB-JOjcBwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_total_rouge(true_labels, predicted_labels):\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    combined_true = \" \".join(true_labels)\n",
        "    combined_predicted = \" \".join(predicted_labels)\n",
        "\n",
        "    total_score = scorer.score(combined_true, combined_predicted)\n",
        "\n",
        "    return total_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_rouge_scores = calculate_total_rouge(true_labels, predicted_labels)\n",
        "print(\"Total ROUGE Scores:\", total_rouge_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA04Fqe2H04E",
        "outputId": "48cec8ea-32a4-48e6-9f81-cf085c03c9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ROUGE Scores: {'rouge1': Score(precision=0.6036939313984169, recall=0.6224156692056583, fmeasure=0.6129118671309939), 'rouge2': Score(precision=0.19429778247096094, recall=0.20032661948829614, fmeasure=0.19726614848566068), 'rougeL': Score(precision=0.25488126649076515, recall=0.26278563656147985, fmeasure=0.2587731047414948)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "def calculate_bleu(true_labels, predicted_labels):\n",
        "\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        references.append([true.split()])\n",
        "        if pred.strip():\n",
        "            hypotheses.append(pred.split())\n",
        "        else:\n",
        "            hypotheses.append([])\n",
        "\n",
        "    smoothing_function = SmoothingFunction().method1\n",
        "    bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smoothing_function)\n",
        "    return bleu_score\n",
        "\n",
        "\n",
        "\n",
        "bleu_score = calculate_bleu(true_labels, predicted_labels)\n",
        "print(\"BLEU Score:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J-1go5yJiSv",
        "outputId": "cd761710-78be-4ffc-e948-85dad40742c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.07261468973171632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "def calculate_llm_similarity(true_labels, predicted_labels, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    similarities = []\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        if pred:\n",
        "            embeddings = model.encode([true, pred], convert_to_tensor=True)\n",
        "            similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()\n",
        "            similarities.append(similarity)\n",
        "        else:\n",
        "            similarities.append(0.0)\n",
        "\n",
        "    return similarities\n",
        "\n",
        "\n",
        "similarities = calculate_llm_similarity(true_labels, predicted_labels)\n",
        "print(\"LLM Similarities:\", similarities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7gpaH9PKIBo",
        "outputId": "03c5f997-4b72-4ca7-b468-ce43eb6532ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Similarities: [0.5643056035041809, 0.7388991713523865, 0.7989909052848816, 0.5674906373023987, 0.7210288047790527, 0.41824185848236084, 0.6289610266685486, 0.45475807785987854, 0.6026619076728821, 0.6113052368164062, 0.8387893438339233, 0.8231927156448364, 0.8016122579574585, 0.7046035528182983, 0.7683147192001343, 0.6723469495773315, 0.8930250406265259, 0.6395443677902222, 0.6476553678512573, 0.7873544096946716, 0.7277991771697998, 0.5868380069732666, 0.5488913059234619, 0.883202850818634, 0.844327449798584, 0.5609667301177979, 0.5519403219223022, 0.6548464298248291, 0.7802248001098633, 0.8870300054550171, 0.8742786645889282, 0.848362922668457, 0.7818562984466553, 0.7282975912094116, 0.5283779501914978, 0.8335415720939636, 0.8447953462600708, 0.813531756401062, 0.8565278053283691, 0.6714909076690674, 0.8899580240249634, 0.7419842481613159, 0.3599957823753357, 0.7064620852470398, 0.8789749145507812, 0.8487503528594971, 0.4657061994075775, 0.7298774719238281, 0.7202070355415344, 0.7188318967819214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(sum(similarities)/len(similarities))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekpBgEniKrb2",
        "outputId": "ba04d032-abd8-4a91-a0b4-e12d9c3318cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7110191571712494"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}